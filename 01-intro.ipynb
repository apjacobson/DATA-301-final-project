{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PolyRatings Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polyratings is a website that allows students at Cal Poly to rate their professors, similar to ratemyprofessors.com. Professors are rated on ability to present material clearly, ability to recognize student difficulties, and an overall rating. In these three categories, professors are ranked on an ABCDF scale, which is converted to an overall polyrating out of 4.0 (4 being the best). When reviewing a professor, students can input some of their own information like the grade they got in the class, what year they are, what class they took with that professor, and why they took the class (major, support, elective or GE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My dataset gathers information on each professor based on their polyratings. The final dataset includes data on what department they teach in, number of evaluations on polyratings, their rating, average letter grade in their class, average grade (number) in their class, proportion of students thaat took their class as a major, support, elective, and GE, the average year of a student in their class, and which college they teach in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The questions I want to answer from this dataset are:\n",
    "* Which college has the best/worst polyratings\n",
    "* Which department has the best/worst polyratings\n",
    "* Which college has the highest/lowest average grade\n",
    "* What does the distribution of major/support/elective/GE classes look like between colleges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer these questions, I will use the following notebooks:\n",
    "* **01-intro** *An introduction to the project, dataset, and the following notebooks.*\n",
    "* **02-inport_tidy** *This notebook imports the .txt file that I got from the polyratings professors list and also scrapes links to each professor's individual page. It then creates a dataframe from data gathered from the individual page and creates a subset of this data (which will be used throught the rest of the project.*\n",
    "* **03-EDA** *This notebook explores the questions above using the subsetted data from the import_tidy notebook.*\n",
    "* **04-model** \n",
    "*This notebook aims to calculate a linear regression equation based on the data. Through the equation we can also answer a few of the above questions.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My challenge area for the project was the import/tidy section. I used two packages that were unfirmiliar to me (beautifulsoup and requests) to scrape the data from the website. The data was also very dirty, so the import and tidying sections are the ones that took the most time and the ones I'm most proud of. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the data I collected is from polyratings.com and polyratings.com/list.php"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
